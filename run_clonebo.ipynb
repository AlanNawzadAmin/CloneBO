{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import torch \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import wandb\n",
    "\n",
    "from pools import get_oracle_and_pool\n",
    "from clonebo.mcmc_proposers import proposer_local_multi, scorer_local\n",
    "from clonebo.seq_tools import print_difs, remove_spaces, is_alph\n",
    "from clonebo import tsmc \n",
    "from clonebo import importance_sample "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('configs/short_run.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load oracles\n",
    "(cost_func, labeled_seqs, labels, (start_mean, start_std), only_cdr\n",
    ") = get_oracle_and_pool(OmegaConf.to_container(cfg.oracle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "model = AutoModelForCausalLM.from_pretrained(\"CloneBO/CloneLM-Heavy\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"CloneBO/CloneLM-Heavy\")\n",
    "tokenizer.seq_sep_token = \"[ClSep]\"\n",
    "tokenizer.seq_sep_token_id = tokenizer.convert_tokens_to_ids(tokenizer.seq_sep_token)\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for sampling\n",
    "args = cfg.likelihoods\n",
    "\n",
    "max_steps = cfg.sample.max_steps\n",
    "n_cond = cfg.sample.n_cond\n",
    "clone_size = cfg.sample.clone_size\n",
    "n_particles = cfg.sample.n_particles\n",
    "n_resample = cfg.sample.n_resample\n",
    "total_mcmc_steps = cfg.sample.total_mcmc_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Load models and set up files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/mcmc_runs'\n",
    "start_name = f'{cfg.oracle.oracle_name}_tm_heavy_r{cfg.run.seed}_nmut{cfg.oracle.n_labelled_mut}'\n",
    "model_fname = f'{cfg.run.name}_n_cond{cfg.sample.n_cond}\\\n",
    "_cl{cfg.sample.clone_size}_ms{cfg.sample.max_steps}\\\n",
    "{'_naive' if cfg.sample.importance_sample else ''}\\\n",
    "_np{cfg.sample.n_particles}_tsmc_sig{args.label_noise_sigma}'\n",
    "os.system(f'mkdir {os.path.join(data_path)}')\n",
    "os.system(f'mkdir {os.path.join(data_path, start_name)}')\n",
    "os.system(f'mkdir {os.path.join(data_path, start_name, model_fname)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Run CloneBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposer = proposer_local_multi\n",
    "    \n",
    "def get_con_inds(start_seq, labeled_seqs, labels, args, model, tokenizer, n_cond):\n",
    "    label_liks = scorer_local([start_seq], labeled_seqs, labeled_seqs, labels,\n",
    "                                             args, model, tokenizer)\n",
    "    return np.argsort(label_liks)[-n_cond:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"log_sampled_clones.npy\" in os.listdir(os.path.join(data_path, start_name, model_fname)) and not cfg.run.redo:\n",
    "    try:\n",
    "        log_sampled_clones = np.load(os.path.join(data_path, start_name, model_fname, \"log_sampled_clones.npy\")).tolist()[:-1]\n",
    "        labeled_seqs = np.load(os.path.join(data_path, start_name, model_fname, \"labeled_seqs.npy\"))[:-1]\n",
    "        labels = np.load(os.path.join(data_path, start_name, model_fname, \"labels.npy\"))[:-1]\n",
    "        print(f\"Loading! Found {len(log_sampled_clones)} previous samples.\")\n",
    "        for i in range(len(log_sampled_clones)):\n",
    "            wandb.log({\n",
    "                \"labeled_seq\": wandb.Html(labeled_seqs[:-i][-1]),\n",
    "                \"label\": labels[:-i][-1],\n",
    "                \"best_label\": labels[:-i].max()\n",
    "            })\n",
    "    except Exception as e:\n",
    "        log_sampled_clones = []\n",
    "else:\n",
    "    log_sampled_clones = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.run.wandb:\n",
    "    wandb.init(project=\"CloneBO\", config=OmegaConf.to_container(cfg, resolve=True))\n",
    "\n",
    "steps = len(log_sampled_clones)\n",
    "while steps < total_mcmc_steps:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    ##### get start and seqs to cond on #####\n",
    "    start = np.random.choice(labeled_seqs[np.argsort(labels)[-n_resample:]])\n",
    "    cond_inds = get_con_inds(start, labeled_seqs, labels, args, model, tokenizer, n_cond) # most likely given start\n",
    "    cond_labels = labels[cond_inds]\n",
    "    cond_seqs = labeled_seqs[cond_inds]\n",
    "\n",
    "    ##### pick first seq in sampled clone #####\n",
    "    init_clone = start\n",
    "\n",
    "    ##### run SMC #####\n",
    "    if not cfg.sample.importance_sample:\n",
    "        smc = tsmc.smc(args, model, tokenizer, n_particles*[init_clone],\n",
    "                       cond_seqs, (cond_labels - start_mean) / start_std,\n",
    "                       sample_one_seq=True, keep_on_gpu=(n_cond<=75))\n",
    "        for i in range(clone_size-1):\n",
    "            print(\"Sampling sequence \", i+1)\n",
    "            ess = smc.run_smc(150, steps_per_update=1 if n_cond<=75 else 20)\n",
    "            smc = tsmc.smc.refresh_smc(args, smc, energy_resample=True)\n",
    "        sampled_clone = smc.get_clones()[0]\n",
    "    else:\n",
    "        smc = importance_sample.smc(args, model, tokenizer, n_particles*[init_clone],\n",
    "                     cond_seqs, (cond_labels - start_mean) / start_std,\n",
    "                     batch_size=75)\n",
    "        for l in range(clone_size-1):\n",
    "            smc.sample_seq()\n",
    "        sampled_clone = smc.importance_sample()\n",
    "\n",
    "    valid_clone = np.all(is_alph(remove_spaces(sampled_clone.split(tokenizer.seq_sep_token))))\n",
    "    if valid_clone:\n",
    "        ##### propose seq #####\n",
    "        proposal = proposer([sampled_clone], labeled_seqs, labels,\n",
    "                            args, model, tokenizer,\n",
    "                            best_seq=labeled_seqs[np.argsort(labels)[-n_resample:]], #start if not preserve_start else \n",
    "                            only_cdr=only_cdr, max_steps=max_steps)[0]\n",
    "        y_new = cost_func(proposal)\n",
    "        steps = steps + 1\n",
    "\n",
    "        ##### log #####\n",
    "        labels = np.r_[labels, [y_new]]        \n",
    "        labeled_seqs = np.r_[labeled_seqs, [proposal]]\n",
    "        log_sampled_clones.append(sampled_clone)\n",
    "        np.save(os.path.join(data_path, start_name, model_fname, 'log_sampled_clones.npy'), log_sampled_clones)\n",
    "        np.save(os.path.join(data_path, start_name, model_fname, 'labeled_seqs.npy'), labeled_seqs)\n",
    "        np.save(os.path.join(data_path, start_name, model_fname, 'labels.npy'), labels)\n",
    "        if cfg.run.wandb:\n",
    "            wandb.log({\n",
    "                \"sampled_clone\": wandb.Table(data=[[line] for line in\n",
    "                sampled_clone.split(tokenizer.seq_sep_token)], columns=[\"Sampled clone\"]),\n",
    "                \"labeled_seq\": wandb.Html(labeled_seqs[-1]),\n",
    "                \"label\": labels[-1],\n",
    "                \"best_label\": labels.max()\n",
    "            })\n",
    "\n",
    "        ##### print results #####\n",
    "        print(f\"\\nRound {steps}:\")\n",
    "        x0 = remove_spaces([start])[0]\n",
    "        print(\"Proposal:\")\n",
    "        print_difs(remove_spaces([proposal])[0], x0, color='black')\n",
    "        print(\"Value of proposal:\", y_new, \"; vs. X0:\", cost_func(start), \"; vs. best:\", labels.max())\n",
    "        print(\"Sampled clone:\")\n",
    "        for seq in remove_spaces(sampled_clone.split(tokenizer.seq_sep_token)):\n",
    "            print_difs(seq, x0, color='black')\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid clone, restarting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bighat2",
   "language": "python",
   "name": "bighat2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
